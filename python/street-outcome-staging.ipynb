{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process London Crime datasets (Street, Outcome and London-Boroughs)\n",
    "Street dataset pre-process before sending to Datawarehouse\n",
    "1. London Crime Street Dataset\n",
    "2. London Crime Outcome Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common activities\n",
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries that require for project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "INPUT_PATH = \"C://SHU/ADMP/Assessment_02/londoncrimedw_project/input_csv/\"\n",
    "OUTPUT_PATH = \"C://SHU/ADMP/Assessment_02/londoncrimedw_project/output_csv/\"\n",
    "\n",
    "# create variables to store the datasets name you want to use\n",
    "STREET_FILENAME = \"street_london.csv\"\n",
    "OUTCOME_FILENAME = \"outcome_london.csv\"\n",
    "BOROUGH_FILENAME = \"london-boroughs-data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare and define functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FILESIZE:\n",
    "    SMALL = 1\n",
    "    LARGE = 2\n",
    "    \n",
    "def read_csv_file(fileType, fileName):\n",
    "    if (fileType == FILESIZE.SMALL):\n",
    "        df_ret = pd.read_csv(fileName)\n",
    "    else:\n",
    "        # read the large csv file with specified chunksize of 10 million records\n",
    "        df_chunk = pd.read_csv(fileName, chunksize=1000000)\n",
    "\n",
    "        # append each chunk df here\n",
    "        chunk_list = []   \n",
    "\n",
    "        # each chunk is in df format\n",
    "        for chunk in df_chunk:    \n",
    "            # once the data filtering is done, append the chunk to list\n",
    "            chunk_list.append(chunk)\n",
    "\n",
    "        # concat the list into dataframe \n",
    "        df_ret = pd.concat(chunk_list)\n",
    "        \n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV files and store them in respective data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a working directory to the location where input dataset csv file exist\n",
    "os.chdir(INPUT_PATH)\n",
    "\n",
    "# load dataframe with street data from CSV file \n",
    "street_df = read_csv_file(FILESIZE.LARGE, STREET_FILENAME)\n",
    "\n",
    "# load dataframe with outcome data from CSV file \n",
    "outcome_df = read_csv_file(FILESIZE.LARGE, OUTCOME_FILENAME)\n",
    "\n",
    "# store london borough data into dataframe\n",
    "london_borough_df = read_csv_file(FILESIZE.SMALL, BOROUGH_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Pre-Processing for London Crime Street Dataset\n",
    "\n",
    "### Handle NULL/Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. Crime_ID: Remove null records from the street data frame.\n",
    "street_df = street_df[street_df.Crime_ID.isnull() == False]\n",
    "\n",
    "# 02. Longitude, Latitude: Fill missing values with 0\n",
    "street_df.Longitude.fillna(0, inplace=True)\n",
    "street_df.Latitude.fillna(0, inplace=True)\n",
    "\n",
    "# 03. LSOA_code, LSOA_name: Fill missing values with 'Not Available' text\n",
    "street_df.LSOA_code.fillna('Not Available', inplace=True)\n",
    "street_df.LSOA_name.fillna('Not Available', inplace=True)\n",
    "\n",
    "# 04. Last_outcome_category: Fill missing values with 'Not Available' text\n",
    "street_df.Last_outcome_category.fillna('Not Available', inplace=True)\n",
    "\n",
    "# 05. Context: Drop it as all fields are empty here. Hence, no significance\n",
    "street_df = street_df.drop(['Context'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete columns which are of not much significance\n",
    "'Reported_by' column is not useful and hence drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Reported_by column from the dataset \n",
    "street_df = street_df.drop(['Reported_by'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive new column for Borough_name from LSOA_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last 5 characters from the LSOA_name (4 code and 1 space)\n",
    "street_df['Borough_name'] = street_df.LSOA_name[(street_df.LSOA_name.isnull()==False)].str[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplication for Crime_ID feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the duplicate records except first instance of it\n",
    "street_df = street_df.drop_duplicates(subset='Crime_ID', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split columns from one to two\n",
    "\n",
    "Split Month column to two columns named, Year and Month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the month column have any null value \n",
    "number_of_null_months = street_df.Month[street_df.Month.isnull() == True].size\n",
    "\n",
    "#  Split  Month column to Year and Month only if their is no null value present inside Month\n",
    "if(number_of_null_months == 0):\n",
    "    # create Year column inside street dataframe and populate year data from the Month field\n",
    "    street_df['Year'] = street_df['Month'].str[: 4]\n",
    "    \n",
    "    # update Month column with just a Month number\n",
    "    street_df['Month'] = street_df['Month'].str[-2: ]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate \"London Borough CSV\" with \"Street Crime CSV\"\n",
    "***\n",
    "### Integration key used to merge between two datasets is 'Borough_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge london_borough with the street data to get relevant records only\n",
    "street_df = pd.merge(left=street_df, right=london_borough_df, left_on='Borough_name', right_on='Name')\n",
    "\n",
    "# Remove un-necessary columns after merging action\n",
    "street_df = street_df.drop(['Id', 'Name'], axis=1)\n",
    "\n",
    "# Get unique london-boroghs numbers\n",
    "street_df.Borough_name.unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Pre-Processing for London Crime Outcome Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do sorting on month basis\n",
    "Outcome dataset sorting on the Month basis is require to bring latest updated outcome on the top for each crime ids and rest will lie beneath. This is important step because only the latest records are going to retain and all previous/historical outcome update would be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the outcome data frame with Month column in descending order to get the latest crime id entry on top\n",
    "outcome_df = outcome_df.sort_values(by='Month', ascending=False)\n",
    "\n",
    "# Test if the latest crime id is appearing on the top \n",
    "# outcome_df[outcome_df.Crime_ID == ('3b60aed0ce6c29f63a00e44822492dcdc419b68a0974e53e6884359dc2aec1aa')].sort_values(by='Month', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate Crime IDs so that only the recent outcome update will be availble in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the duplicate records except first instance of it\n",
    "outcome_df = outcome_df.drop_duplicates(subset='Crime_ID', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename 'Outcome_type' column to 'Latest_Outcome_type' for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Outcome_type to Latest_outcome_type\n",
    "outcome_df.rename(columns = {'Outcome_type':'Latest_Outcome_type'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only the required features inside the outcome dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need only two columns from the dataset and hence extract the required ones\n",
    "outcome_df = outcome_df[['Crime_ID','Latest_Outcome_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate \"London Borough CSV\" with \"Outcome CSV\"\n",
    "***\n",
    "### Integration key used to merge between two dataset is 'Crime_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the left outer joining so that all street data will be retained along with the joined outcome data\n",
    "street_df = pd.merge(left=street_df, right=outcome_df, on='Crime_ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace all empty/null 'Latest_outcome_type' with the 'Last_outcome_category' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace null values with 'Last_outcome_category' text\n",
    "street_df.Latest_Outcome_type.fillna(street_df['Last_outcome_category'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove \"Last_outcome_category\" and retain the \"Latest outcome category\" only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Last_outcome_category\n",
    "street_df = street_df.drop(['Last_outcome_category'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the \"Crime_ID\" to \"Crime_hashcode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_df.rename(columns = {'Crime_ID':'Crime_hashcode'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed dataframe to csv file in the output path location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_df.to_csv(OUTPUT_PATH+\"street-staging-data.csv\", sep=',', encoding='utf-8', index=None, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
