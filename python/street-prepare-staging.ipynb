{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street dataset pre-process before sending to Datawarehouse\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries that require for project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "INPUT_PATH = \"C://SHU/ADMP/Assessment_02/londoncrimedw_project/input_csv/\"\n",
    "OUTPUT_PATH = \"C://SHU/ADMP/Assessment_02/londoncrimedw_project/output_csv/\"\n",
    "\n",
    "# create variables to store the datasets name you want to use\n",
    "STREET_FILENAME = \"street_london.csv\"\n",
    "LONDON_BOROUGH_FILENAME = \"london_boroughs.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FILESIZE:\n",
    "    SMALL = 1\n",
    "    LARGE = 2\n",
    "    \n",
    "def read_csv_file(fileType, fileName):\n",
    "    if (fileType == FILESIZE.SMALL):\n",
    "        df_ret = pd.read_csv(fileName)\n",
    "    else:\n",
    "        # read the large csv file with specified chunksize of 10 million records\n",
    "        df_chunk = pd.read_csv(fileName, chunksize=1000000)\n",
    "\n",
    "        # append each chunk df here\n",
    "        chunk_list = []   \n",
    "\n",
    "        # each chunk is in df format\n",
    "        for chunk in df_chunk:    \n",
    "            # once the data filtering is done, append the chunk to list\n",
    "            chunk_list.append(chunk)\n",
    "\n",
    "        # concat the list into dataframe \n",
    "        df_ret = pd.concat(chunk_list)\n",
    "        \n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File london_boroughs.csv does not exist: 'london_boroughs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-cc2a6d85a8f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# store london borough data into dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mlondon_borough_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_csv_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFILESIZE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSMALL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLONDON_BOROUGH_FILENAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-2046ed76c74e>\u001b[0m in \u001b[0;36mread_csv_file\u001b[1;34m(fileType, fileName)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_csv_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfileType\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFILESIZE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSMALL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mdf_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# read the large csv file with specified chunksize of 10 million records\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File london_boroughs.csv does not exist: 'london_boroughs.csv'"
     ]
    }
   ],
   "source": [
    "# set a working directory to the location where input dataset csv file exist\n",
    "os.chdir(INPUT_PATH)\n",
    "\n",
    "# load dataframe with street data from CSV file \n",
    "street_df = read_csv_file(FILESIZE.LARGE, STREET_FILENAME)\n",
    "\n",
    "# store london borough data into dataframe\n",
    "# london_borough_df = read_csv_file(FILESIZE.SMALL, LONDON_BOROUGH_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle NULL/Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. Crime_ID: Remove null records from the street data frame.\n",
    "street_df = street_df[street_df.Crime_ID.isnull() == False]\n",
    "\n",
    "# 02. Longitude, Latitude: Fill missing values with 0\n",
    "street_df.Longitude.fillna(0, inplace=True)\n",
    "street_df.Latitude.fillna(0, inplace=True)\n",
    "\n",
    "# 03. LSOA_code, LSOA_name: Fill missing values with 'Not Available' text\n",
    "street_df.LSOA_code.fillna('Not Available', inplace=True)\n",
    "street_df.LSOA_name.fillna('Not Available', inplace=True)\n",
    "\n",
    "# 04. Last_outcome_category: Fill missing values with 'Not Available' text\n",
    "street_df.Last_outcome_category.fillna('Not Available', inplace=True)\n",
    "\n",
    "# 05. Context: Drop it as all fields are empty here. Hence, no significance\n",
    "street_df = street_df.drop(['Context'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete columns which are of not much significance\n",
    "'Reported_by' column is not useful and hence drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Reported_by column from the dataset \n",
    "street_df = street_df.drop(['Reported_by'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive new column for Borough_name from LSOA_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last 5 characters from the LSOA_name (4 code and 1 space)\n",
    "street_df['Borough_name'] = street_df.LSOA_name[(street_df.LSOA_name.isnull()==False)].str[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplication for Crime_ID feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the duplicate records except first instance of it\n",
    "street_df = street_df.drop_duplicates(subset='Crime_ID', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split columns from one to two\n",
    "\n",
    "Split Month column to two columns named, Year and Month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Falls_within</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>LSOA_code</th>\n",
       "      <th>LSOA_name</th>\n",
       "      <th>Crime_type</th>\n",
       "      <th>Last_outcome_category</th>\n",
       "      <th>Borough_name</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04f04430a130fa6aa5a5c6ef1021a942c16cca642529dc...</td>\n",
       "      <td>12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Location</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Violence and sexual offences</td>\n",
       "      <td>Under investigation</td>\n",
       "      <td>Not Avai</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e1bc0b282acfa132e77dadc63efed5a0d22ea969f39e72...</td>\n",
       "      <td>12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Location</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Violence and sexual offences</td>\n",
       "      <td>Under investigation</td>\n",
       "      <td>Not Avai</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c55afa311916b68a3a3b8ac25ba37d4fcbfbb8ceb7a315...</td>\n",
       "      <td>12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Location</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Violence and sexual offences</td>\n",
       "      <td>Under investigation</td>\n",
       "      <td>Not Avai</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95cb59cbe07660643794f3286e3e177dd1c99e907aae55...</td>\n",
       "      <td>12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Location</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Violence and sexual offences</td>\n",
       "      <td>Under investigation</td>\n",
       "      <td>Not Avai</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03f070e00ef7b4e299c95a5f4e2c956587b2748e3380a3...</td>\n",
       "      <td>12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Location</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Violence and sexual offences</td>\n",
       "      <td>Under investigation</td>\n",
       "      <td>Not Avai</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>daabf74598d41568679de0222cd9c9b3a8b2550b83b18a...</td>\n",
       "      <td>12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Location</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Violence and sexual offences</td>\n",
       "      <td>Under investigation</td>\n",
       "      <td>Not Avai</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4a130ebf01558600886bac2a26d01e76239e45d5b85c29...</td>\n",
       "      <td>12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Location</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Violence and sexual offences</td>\n",
       "      <td>Under investigation</td>\n",
       "      <td>Not Avai</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d83a8f832de935c83562db8f662830f5d639da7630e23a...</td>\n",
       "      <td>12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Location</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Violence and sexual offences</td>\n",
       "      <td>Under investigation</td>\n",
       "      <td>Not Avai</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ca109136525fb40a61c7a5d4398ac343baad02fa7c9c6d...</td>\n",
       "      <td>12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Location</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Violence and sexual offences</td>\n",
       "      <td>Under investigation</td>\n",
       "      <td>Not Avai</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0bf227c136793c7cfcd55eb4f2eedd49679d4f99027a1e...</td>\n",
       "      <td>12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Location</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Violence and sexual offences</td>\n",
       "      <td>Under investigation</td>\n",
       "      <td>Not Avai</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Crime_ID Month  \\\n",
       "0  04f04430a130fa6aa5a5c6ef1021a942c16cca642529dc...    12   \n",
       "1  e1bc0b282acfa132e77dadc63efed5a0d22ea969f39e72...    12   \n",
       "2  c55afa311916b68a3a3b8ac25ba37d4fcbfbb8ceb7a315...    12   \n",
       "3  95cb59cbe07660643794f3286e3e177dd1c99e907aae55...    12   \n",
       "4  03f070e00ef7b4e299c95a5f4e2c956587b2748e3380a3...    12   \n",
       "5  daabf74598d41568679de0222cd9c9b3a8b2550b83b18a...    12   \n",
       "6  4a130ebf01558600886bac2a26d01e76239e45d5b85c29...    12   \n",
       "7  d83a8f832de935c83562db8f662830f5d639da7630e23a...    12   \n",
       "8  ca109136525fb40a61c7a5d4398ac343baad02fa7c9c6d...    12   \n",
       "9  0bf227c136793c7cfcd55eb4f2eedd49679d4f99027a1e...    12   \n",
       "\n",
       "            Falls_within  Longitude  Latitude     Location      LSOA_code  \\\n",
       "0  City of London Police        0.0       0.0  No Location  Not Available   \n",
       "1  City of London Police        0.0       0.0  No Location  Not Available   \n",
       "2  City of London Police        0.0       0.0  No Location  Not Available   \n",
       "3  City of London Police        0.0       0.0  No Location  Not Available   \n",
       "4  City of London Police        0.0       0.0  No Location  Not Available   \n",
       "5  City of London Police        0.0       0.0  No Location  Not Available   \n",
       "6  City of London Police        0.0       0.0  No Location  Not Available   \n",
       "7  City of London Police        0.0       0.0  No Location  Not Available   \n",
       "8  City of London Police        0.0       0.0  No Location  Not Available   \n",
       "9  City of London Police        0.0       0.0  No Location  Not Available   \n",
       "\n",
       "       LSOA_name                    Crime_type Last_outcome_category  \\\n",
       "0  Not Available  Violence and sexual offences   Under investigation   \n",
       "1  Not Available  Violence and sexual offences   Under investigation   \n",
       "2  Not Available  Violence and sexual offences   Under investigation   \n",
       "3  Not Available  Violence and sexual offences   Under investigation   \n",
       "4  Not Available  Violence and sexual offences   Under investigation   \n",
       "5  Not Available  Violence and sexual offences   Under investigation   \n",
       "6  Not Available  Violence and sexual offences   Under investigation   \n",
       "7  Not Available  Violence and sexual offences   Under investigation   \n",
       "8  Not Available  Violence and sexual offences   Under investigation   \n",
       "9  Not Available  Violence and sexual offences   Under investigation   \n",
       "\n",
       "  Borough_name  Year  \n",
       "0     Not Avai  2019  \n",
       "1     Not Avai  2019  \n",
       "2     Not Avai  2019  \n",
       "3     Not Avai  2019  \n",
       "4     Not Avai  2019  \n",
       "5     Not Avai  2019  \n",
       "6     Not Avai  2019  \n",
       "7     Not Avai  2019  \n",
       "8     Not Avai  2019  \n",
       "9     Not Avai  2019  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the month column have any null value \n",
    "number_of_null_months = street_df.Month[street_df.Month.isnull() == True].size\n",
    "\n",
    "#  Split  Month column to Year and Month only if their is no null value present inside Month\n",
    "if(number_of_null_months == 0):\n",
    "    # create Year column inside street dataframe and populate year data from the Month field\n",
    "    street_df['Year'] = street_df['Month'].str[: 4]\n",
    "    \n",
    "    # update Month column with just a Month number\n",
    "    street_df['Month'] = street_df['Month'].str[-2: ]\n",
    "    \n",
    "street_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed dataframe to csv file in the output path location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_df.to_csv(OUTPUT_PATH+\"street-staging-data.csv\", sep=',', encoding='utf-8', index=None, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
